---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---
## Contact
* jack [at] jbkjr.[first 3 letters of "commercial"]
* john.koch [at] yale.[first 3 letters of "education"]

## Education
* [**Yale University**](http://yale.edu), New Haven, Connecticut, USA
  * B.S. in [Applied Mathematics](https://applied.math.yale.edu/)
    * Thesis: Tree-to-Tree Semantic Parsing
      * Adviser: Prof. Dragomir Radev
    * Concentration: Computer Science.
    * Awards: George J. Schulz Summer Fellowship in the Physical Sciences
    * Relevant Coursework: Artificial Intelligence, Data Mining & Machine Learning, Natural Language Processing, Deep Learning Theory & Applications, Advanced Natural Language Processing, Selected Topics in Neural Nets, Data Analysis, Optimization Techniques

* [**Stanford University**](http://stanford.edu), Stanford, California,
USA
  * Summer Program
    * Classwork in Stochastic Processes and Real Analysis

## Related Experience
* [**Language, Information, and Learning at
Yale**](https://yale-lily.github.io/), Yale University
  * Undergraduate Research Student, Nov. 2017 to May 2018, Sep. 2018 to Dec. 2018
    * Developed and implemented machine learning models in the domain of natural language processing
    * Utilized tree-based architectures for semantic parsing (Spring 2018)
    * Developed and tested a new “Temporal Capsule Net” architecture on Visual-QA tasks (Spring 2018)
    * Selected to supervise undergraduate research applying the Transformer architecture to text-to-SQL tasks (Fall 2018)
    * Applied and compared unsupervised pre-training techniques to text generation task of semantic parsing (Fall 2018)
  * Research Assistant, Jun. 2018 to Aug. 2018
    * Applied the Transformer architecture to language modeling tasks
    * Aided initial data scraping and analysis for new “BioNLP” project in conjunction with Yale School of Medicine

## Projects
* [**Comparing Pre-trained Language Models with Semantic Parsing**](https://jbkjr.com/posts/2019/01/unsupervised_pretraining_comparison/)
  * First application of pre-trained language models to semantic parsing and the first application of the recent ELMo, OpenAI GPT, and BERT language models to any language generation task
  * Most significant project undertaken individually
* [**Tree2Tree: A Reimplementation and Discussion of Tree-Based Neural Semantic Parsing**](https://jbkjr.com/files/tree_sempar_final.pdf)
  * Compared sequence-to-sequence, sequence-to-tree, and novel tree-to-tree architectures for semantic parsing
  * Contributions to this project satisfied senior thesis requirements

## Skills
* Computer Languages: Python, PyTorch, TensorFlow, C, Java, LaTeX, R, Racket

## Interests
* Consumer technology, cinema, philosophy.

## References
* **Professor Dragomir Radev**, Yale University
  * dragomir.radev [at] yale.[first 3 letters of "education"]
